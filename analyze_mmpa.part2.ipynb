{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem \n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "def applyParallel(df, func):\n",
    "    df_split = np.array_split(df, cpu_count())\n",
    "    pool = Pool(cpu_count())\n",
    "    data = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n",
    "\n",
    "def normalize_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return Chem.MolToSmiles(mol, isomericSmiles=False)\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "def normalize_smiles_series(smiles_series):\n",
    "    return smiles_series.map(normalize_smiles)\n",
    "\n",
    "\n",
    "def generate_murcko_scaffold(smile):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        if mol:\n",
    "            scaffold = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "            return Chem.MolToSmiles(scaffold, isomericSmiles=False)\n",
    "        else:\n",
    "            return np.NaN\n",
    "    except:\n",
    "        return np.NaN\n",
    "    \n",
    "\n",
    "def generate_topological_scaffold(smile):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        if mol:\n",
    "            scaffold = MurckoScaffold.MakeScaffoldGeneric(MurckoScaffold.GetScaffoldForMol(mol))\n",
    "            return Chem.MolToSmiles(scaffold, isomericSmiles=False)\n",
    "        else:\n",
    "            return np.NaN\n",
    "    except:\n",
    "        return np.NaN\n",
    "\n",
    "\n",
    "    \n",
    "                   \n",
    "def generate_murcko_scaffold_series(data):\n",
    "    return data.map(generate_murcko_scaffold)\n",
    "\n",
    "def generate_topological_scaffold_series(data):\n",
    "    return data.map(generate_topological_scaffold)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True,fastmath=True)\n",
    "def find_nns(fps, references):\n",
    "    all_nns = np.zeros((fps.shape[0], 3), dtype=np.float64)\n",
    "    \n",
    "    for i in prange(fps.shape[0]):\n",
    "        nn_dist, nn_idx, avg_nn = _find_nn_and_avg_nn(fps[i], references)\n",
    "        all_nns[i,0] = nn_dist\n",
    "        all_nns[i,1] = nn_idx\n",
    "        all_nns[i,2] = avg_nn\n",
    "    \n",
    "    return all_nns\n",
    "    \n",
    "@njit(fastmath=True)\n",
    "def _find_nn_and_avg_nn(fp, fps):\n",
    "    nn_dist = 0.0\n",
    "    nn_idx = numba.int32(-1)\n",
    "    avg_nn = 0.0\n",
    "    \n",
    "    for i in range(fps.shape[0]):\n",
    "        tanimoto = _minmax_two_fp(fp, fps[i])\n",
    "        avg_nn += tanimoto\n",
    "        if tanimoto > nn_dist:\n",
    "            nn_dist = tanimoto\n",
    "            nn_idx = i\n",
    "    avg_nn = numba.float64(avg_nn) / numba.float64(fps.shape[0])\n",
    "            \n",
    "    return nn_dist, nn_idx, avg_nn\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def _minmax_two_fp(fp1, fp2):\n",
    "    common = numba.int32(0)\n",
    "    maxnum = numba.int32(0)\n",
    "    i = 0\n",
    "\n",
    "    while i < len(fp1):\n",
    "        min_ = fp1[i]\n",
    "        max_ = fp2[i]\n",
    "\n",
    "        if min_ > max_:\n",
    "            min_ = fp2[i]\n",
    "            max_ = fp1[i]\n",
    "\n",
    "        common += min_\n",
    "        maxnum += max_\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return numba.float64(common) / numba.float64(maxnum)\n",
    "\n",
    "def counted_tanimoto_similarity(f1, fp2, return_distance=True):\n",
    "    if return_distance:\n",
    "        return 1. - _minmax_two_fp(fp1,fp2)\n",
    "    else:\n",
    "        return _minmax_two_fp(fp1,fp2)\n",
    "    \n",
    "def bulk_counted_tanimoto(fp1, fps, return_distance=True):\n",
    "    if return_distance:\n",
    "        return [1. - _minmax_two_fp(fp1,fp2) for fp2 in fps]\n",
    "    else: \n",
    "        return [_minmax_two_fp(fp1,fp2) for fp2 in fps]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OVERWRITE_FILES = False\n",
    "\n",
    "\n",
    "def read_scaffold_memory(folder):\n",
    "    memory = pd.read_csv(f\"data/memories/{folder}/memory_preprocessed.csv.gz\")\n",
    "    return memory\n",
    "\n",
    "def read_id_steps(folder):\n",
    "    return read_scaffold_memory(folder)[[\"ID\",\"step\",\"total_score\"]]\n",
    "\n",
    "\n",
    "def read_mmp_and_filter_pairs(mmpfile):\n",
    "    foldername = mmpfile.split(\"/\")[1]\n",
    "    target = foldername.split(\"_\")\n",
    "\n",
    "    filtername = target[1]\n",
    "    target = target[0]\n",
    "\n",
    "    df = pd.read_csv(mmpfile, header=None)\n",
    "    df.columns = [\"SMILES_OF_LEFT_MMP\",\"SMILES_OF_RIGHT_MMP\",\"ID_OF_LEFT_MMP\",\"ID_OF_RIGHT_MMP\",\"SMIRKS_OF_TRANSFORMATION\",\"SMILES_OF_CONTEXT\"]\n",
    "\n",
    "    df[\"SET_OF_LEFT_MMP\"] = df[\"ID_OF_LEFT_MMP\"].map(lambda x: x.split(\"_\")[2] )\n",
    "    df[\"SET_OF_RIGHT_MMP\"] = df[\"ID_OF_RIGHT_MMP\"].map(lambda x: x.split(\"_\")[2] )\n",
    "\n",
    "\n",
    "    mmp_pairs = df.query(\" SET_OF_LEFT_MMP == @filtername and (SET_OF_RIGHT_MMP == 'training' or SET_OF_RIGHT_MMP == 'test' or SET_OF_RIGHT_MMP == 'validation' )\")\n",
    "    ids = read_id_steps(foldername)\n",
    "    \n",
    "    mmp_pairs = pd.merge(mmp_pairs, ids, left_on=\"ID_OF_LEFT_MMP\", right_on=\"ID\", how=\"inner\")\n",
    "    del mmp_pairs[\"ID\"]\n",
    "    mmp_pairs.rename(columns={\"step\": \"STEP\", \"total_score\": \"SCORE\"}, inplace=True)\n",
    "    mmp_pairs = mmp_pairs.sort_values(by=['STEP'])\n",
    "    return mmp_pairs\n",
    "\n",
    "\n",
    "for mmpfile in glob(\"MMP/*/MMP.csv.gz\"):\n",
    "    folder = mmpfile.split(\"/\")[1]\n",
    "    if len(folder.split(\"_\")) <= 2: #we only process the run with explicit parameters here in this notebook\n",
    "        continue \n",
    "    mmpfile_filtered = mmpfile.replace(\"MMP.csv.gz\", \"MMP_filtered.csv\")\n",
    "    if not os.path.exists(mmpfile_filtered) or OVERWRITE_FILES:\n",
    "        mmp = read_mmp_and_filter_pairs(mmpfile)\n",
    "        mmp.to_csv(mmpfile_filtered, index=False)\n",
    "    else:\n",
    "        #print(f\"Skipping {mmpfile} as it seems to already be processed\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_mmp_stats(mmp_pairs):\n",
    "        nb_mmp_pairs = len(mmp_pairs)\n",
    "        nb_generated_unique_cpds = len(mmp_pairs.drop_duplicates(\"SMILES_OF_LEFT_MMP\"))\n",
    "        return nb_mmp_pairs, nb_generated_unique_cpds\n",
    "    \n",
    "\n",
    "def get_mmp_cpd(df, filtername, maxstep, minactivity):\n",
    "    mmp_pairs = df.query(\"SET_OF_LEFT_MMP == @filtername and STEP < @maxstep and SCORE >= @minactivity\").copy()\n",
    "    \n",
    "    mmp_pairs = mmp_pairs.sort_values(by=['STEP'])\n",
    "    mmp_pairs = mmp_pairs.drop_duplicates([\"SMILES_OF_LEFT_MMP\", \"SMILES_OF_RIGHT_MMP\"], keep='first')\n",
    "        \n",
    "    np_mmp_pairs_training, nb_generated_unique_cpds_training = _get_mmp_stats(mmp_pairs.query(\"SET_OF_RIGHT_MMP == 'training'\"))\n",
    "    np_mmp_pairs_test, nb_generated_unique_cpds_test = _get_mmp_stats(mmp_pairs.query(\"SET_OF_RIGHT_MMP == 'test' or SET_OF_RIGHT_MMP == 'validation'\"))\n",
    "    \n",
    "    return np_mmp_pairs_training, nb_generated_unique_cpds_training, np_mmp_pairs_test, nb_generated_unique_cpds_test#, np_mmp_pairs_validation, nb_generated_unique_cpds_validation\n",
    "\n",
    "\n",
    "def load_mmp(target, filtername, maxstep, minactivity, minsimilarity=None, bucket_size = None, outputmode = None, temperature = None, experience_replay = None):\n",
    "    if minsimilarity is not None:\n",
    "        file = glob(f\"MMP/{target}_{filtername}_{minsimilarity}_{bucket_size}_{outputmode}_{temperature}_{experience_replay}/MMP_filtered.csv\")\n",
    "    else:\n",
    "        file = glob(f\"MMP/{target}_{filtername}/MMP_filtered.csv\")\n",
    "    if len(file) != 1: \n",
    "        raise Exception(\"Invalid Experiment\")\n",
    "    df = pd.read_csv(file[0])\n",
    "    return get_mmp_cpd(df, filtername, maxstep, minactivity)\n",
    "\n",
    "\n",
    "target_params = {\n",
    "    \"DRD2\":      {\"maxstep\": 300,\n",
    "                  \"minactivity\": 0.7}\n",
    "}\n",
    "\n",
    "bucket_sizes = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75]\n",
    "minsimilarities = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "outputmodes = [\"binary\", \"sigmoid\", \"linear\"]\n",
    "temperatures = [1.0, 1.25, 1.5, 1.75, 2.0]\n",
    "experience_replays = [False, True]\n",
    "\n",
    "\n",
    "default_bucket_size = 25\n",
    "default_minsimilarity = 0.6\n",
    "default_outputmode = \"binary\"\n",
    "default_temperature = 1.0\n",
    "default_experience_replay = False\n",
    "\n",
    "valid_experiments = [] \n",
    "\n",
    "filternames = [\"NoFilter\", \"CompoundSimilarity\", \"IdenticalMurckoScaffold\", \"IdenticalTopologicalScaffold\", \"ScaffoldSimilarity\"]\n",
    "filternames_in_plots = [ \"No memory\", \"CompoundSimilarity memory\", \"IdenticalMurckoScaffold memory\", \"IdenticalCarbonSkeleton memory\", \"ScaffoldSimilarity memory\"]\n",
    "\n",
    "mmp_memories = {}\n",
    "for target, params in target_params.items():\n",
    "    if target not in mmp_memories:\n",
    "        mmp_memories[target] = {} \n",
    "    maxstep = params['maxstep']\n",
    "    minactivity = params['minactivity']\n",
    "    \n",
    "    for filtername, bucket_size, minsimilarity, outputmode, temperature, experience_replay in itertools.product(filternames, bucket_sizes, minsimilarities, outputmodes, temperatures, experience_replays):\n",
    "        try: \n",
    "            nb_mmp_pairs_training, nb_generated_unique_cpds_training, np_mmp_pairs_test, nb_generated_unique_cpds_test = load_mmp(target, filtername, maxstep, minactivity, minsimilarity, bucket_size, outputmode, temperature, experience_replay)\n",
    "            valid_experiments.append((target, filtername, minsimilarity, bucket_size, outputmode, temperature, experience_replay))\n",
    "            experiment = \"_\".join(map(str,valid_experiments[-1]))\n",
    "        except Exception as e:\n",
    "             continue \n",
    "        \n",
    "        print(f\"{experiment} STEPS: {maxstep}\")\n",
    "        print(f\"Training: {nb_mmp_pairs_training} MMPs formed by generating {nb_generated_unique_cpds_training} compounds.\")\n",
    "        print(f\"Test: {np_mmp_pairs_test} MMPs formed by generating {nb_generated_unique_cpds_test} compounds.\")\n",
    "        print()\n",
    "\n",
    "\n",
    "        mmp_memories[experiment] = {} \n",
    "        folder = glob(f\"MMP/{experiment}\")[0].split(\"/\")[-1]\n",
    "        memory = read_scaffold_memory(folder)\n",
    "        memory.rename(columns={\"step\": \"STEP\", \"total_score\": \"SCORE\"}, inplace=True)\n",
    "        memory = memory.sort_values(by=['STEP'])\n",
    "        mmp_memories[experiment] = memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERWRITE_FILES = False\n",
    "\n",
    "\n",
    "def cecfp6_from_mol(mol):\n",
    "    fp = AllChem.GetMorganFingerprint(mol, 3, useCounts=True, useFeatures=False)\n",
    "    size = 2048\n",
    "    nfp = np.zeros(size, np.int32)\n",
    "    for idx,v in fp.GetNonzeroElements().items():\n",
    "        nidx = idx%size\n",
    "        nfp[nidx] += int(v)\n",
    "    return nfp\n",
    "\n",
    "def cecfp6_from_smiles(smiles):\n",
    "    return cecfp6_from_mol(Chem.MolFromSmiles(smiles))\n",
    "\n",
    "def generate_fingerprint_series(data):\n",
    "    return data.map(cecfp6_from_smiles)\n",
    "\n",
    "\n",
    "def find_nns_from_pandas(fps, reference):\n",
    "    fps = np.array([np.array(e) for e in fps.values],dtype=np.int32)\n",
    "    reference = np.array([np.array(e) for e in reference.values],dtype=np.int32)\n",
    "    return find_nns(fps, reference)\n",
    "\n",
    "\n",
    "for target, params in target_params.items():\n",
    "    reference = pd.read_pickle(f\"data/{target}/actives.pkl.gz\")\n",
    "    if target == \"clogP\":\n",
    "        reference['cfp'] = applyParallel( reference[\"SMILES\"], generate_fingerprint_series)\n",
    "\n",
    "    reference_training = reference.query(\"trainingset_class == 'training'\").copy()\n",
    "\n",
    "    reference_test =  reference.query(\"trainingset_class == 'test' or trainingset_class == 'validation'\").copy()\n",
    "\n",
    "    \n",
    "    for experiment_parts in valid_experiments:\n",
    "        if target != experiment_parts[0]:\n",
    "            continue\n",
    "        experiment = \"_\".join(map(str,experiment_parts))\n",
    "\n",
    "        if not os.path.exists(f\"data/memories/{experiment}/memory_with_nn.pkl.gz\") or OVERWRITE_FILES:\n",
    "            memory = pd.read_csv(f\"data/memories/{experiment}/memory_preprocessed.csv.gz\")\n",
    "            memory.rename(columns={\"step\": \"STEP\", \"total_score\": \"SCORE\"}, inplace=True)\n",
    "            memory['cfp'] = applyParallel( memory[\"SMILES\"], generate_fingerprint_series)\n",
    "\n",
    "            nns_arr = find_nns_from_pandas(memory['cfp'], reference['cfp'])\n",
    "\n",
    "            memory[\"NN_dist\"] = nns_arr[:,0]\n",
    "            memory[\"NN_idx\"] = nns_arr[:,1]\n",
    "            memory[\"NN_avg\"] = nns_arr[:,2]\n",
    "            memory[\"NN_Original_Entry_ID\"] = reference.iloc[nns_arr[:,1]][\"Original_Entry_ID\"].values\n",
    "            memory[\"NN_RDKIT_SMILES\"] = reference.iloc[nns_arr[:,1]][\"RDKIT_SMILES\"].values\n",
    "            memory[\"NN_ID\"] = reference.iloc[nns_arr[:,1]][\"ID\"].values\n",
    "\n",
    "            nns_arr = find_nns_from_pandas(memory['cfp'], reference_training['cfp'])\n",
    "\n",
    "            memory[\"NN_dist_training\"] = nns_arr[:,0]\n",
    "            memory[\"NN_idx_training\"] = nns_arr[:,1]\n",
    "            memory[\"NN_avg_training\"] = nns_arr[:,2]\n",
    "            memory[\"NN_Original_Entry_ID_training\"] = reference_training.iloc[nns_arr[:,1]][\"Original_Entry_ID\"].values\n",
    "            memory[\"NN_RDKIT_SMILES_training\"] = reference_training.iloc[nns_arr[:,1]][\"RDKIT_SMILES\"].values\n",
    "            memory[\"NN_ID_training\"] = reference_training.iloc[nns_arr[:,1]][\"ID\"].values\n",
    "\n",
    "            nns_arr = find_nns_from_pandas(memory['cfp'], reference_test['cfp'])\n",
    "\n",
    "            memory[\"NN_dist_test\"] = nns_arr[:,0]\n",
    "            memory[\"NN_idx_test\"] = nns_arr[:,1]\n",
    "            memory[\"NN_avg_test\"] = nns_arr[:,2]\n",
    "            memory[\"NN_Original_Entry_ID_test\"] = reference_test.iloc[nns_arr[:,1]][\"Original_Entry_ID\"].values\n",
    "            memory[\"NN_RDKIT_SMILES_test\"] = reference_test.iloc[nns_arr[:,1]][\"RDKIT_SMILES\"].values\n",
    "            memory[\"NN_ID__test\"] = reference_test.iloc[nns_arr[:,1]][\"ID\"].values\n",
    "\n",
    "            memory.to_pickle(f\"data/memories/{experiment}/memory_with_nn.pkl.gz\")\n",
    "        else:\n",
    "            #print(f\"Skipping data/memories/{experiment}/memory_with_nn.pkl.gz as it seems to already be processed\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumsum_per_target(memory, STEPS, whattoplot=\"SMILES\"):\n",
    "    nb_stuff = []\n",
    "    stuff = set()\n",
    "\n",
    "    for i in range(1,STEPS+1):\n",
    "        subset = memory[memory[\"STEP\"] == i-1]\n",
    "        for s in subset[whattoplot]:\n",
    "            stuff.add(s)\n",
    "        nb_stuff.append(len(stuff))\n",
    "    \n",
    "    return nb_stuff\n",
    "\n",
    "cumsum = dict()\n",
    "memories = dict()\n",
    "for target, params in target_params.items():\n",
    "    cumsum[target] = dict()\n",
    "    memories[target] = dict()\n",
    "    maxstep = params['maxstep']\n",
    "    minactivity = params['minactivity']\n",
    "    for experiment_parts in valid_experiments:\n",
    "        if target != experiment_parts[0]:\n",
    "            continue    \n",
    "        experiment = \"_\".join(map(str,experiment_parts))\n",
    "        memory = pd.read_pickle(f\"data/memories/{experiment}/memory_with_nn.pkl.gz\")\n",
    "        memory.rename(columns={\"step\": \"STEP\", \"total_score\": \"SCORE\"}, inplace=True)\n",
    "        memories[target][experiment] = memory\n",
    "        subset = memory.query(\"STEP < @maxstep and SCORE >= @minactivity\")\n",
    "        cumsum[target][experiment] = dict()\n",
    "        for stuff in [\"SMILES\", \"Murcko Scaffold\", \"Topological Scaffold\"]: \n",
    "            subset = subset.query(\"NN_dist >= 0.4\")\n",
    "            cumsum[target][experiment][stuff] = get_cumsum_per_target(subset, maxstep, stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumsum_per_target(memory, STEPS, whattoplot=\"SMILES\"):\n",
    "    nb_stuff = []\n",
    "    stuff = set()\n",
    "\n",
    "    for i in range(1,STEPS+1):\n",
    "        subset = memory[memory[\"STEP\"] == i-1]\n",
    "        for s in subset[whattoplot]:\n",
    "            stuff.add(s)\n",
    "        nb_stuff.append(len(stuff))\n",
    "    \n",
    "    return nb_stuff\n",
    "\n",
    "for target, params in target_params.items():\n",
    "    if target not in cumsum:\n",
    "        cumsum[target] = dict()\n",
    "    if target not in memories:\n",
    "        memories[target] = dict()\n",
    "    maxstep = params['maxstep']\n",
    "    minactivity = params['minactivity']    \n",
    "    for filtername in filternames:\n",
    "        memory = pd.read_pickle(f\"data/memories/{target}_{filtername}/memory_with_nn.pkl.gz\")\n",
    "        memory.rename(columns={\"step\": \"STEP\", \"total_score\": \"SCORE\"}, inplace=True)\n",
    "        memories[target][filtername] = memory\n",
    "        subset = memory.query(\"STEP < @maxstep and SCORE >= @minactivity\")\n",
    "        cumsum[target][filtername] = dict()\n",
    "        for stuff in [\"SMILES\", \"Murcko Scaffold\", \"Topological Scaffold\"]: \n",
    "            subset = subset.query(\"NN_dist >= 0.4\")\n",
    "            cumsum[target][filtername][stuff] = get_cumsum_per_target(subset, maxstep, stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.read_pickle(\"data/memories/DRD2_IdenticalMurckoScaffold/memory_with_nn.pkl.gz\").rename(columns={\"step\": \"STEP\", \"total_score\": \"SCORE\"}).query(\"STEP < 300 and SCORE >= 0.7\").SMILES.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.read_pickle(\"data/memories/DRD2_IdenticalMurckoScaffold_0.6_25_sigmoid_1.0_False/memory_with_nn.pkl.gz\").rename(columns={\"step\": \"STEP\", \"total_score\": \"SCORE\"}).query(\"STEP < 300 and SCORE >= 0.7\").SMILES.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_names(filtername, bucket_size=25, minsimilarity=0.6, outputmode=\"binary\", temperature=1.0, experience_replay=False):\n",
    "    experiment_string = f\"DRD2_{filtername}_{minsimilarity}_{bucket_size}_{outputmode}_{temperature}_{experience_replay}\"\n",
    "    if experiment_string in cumsum[\"DRD2\"]:\n",
    "        return experiment_string\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_experiment_names(\"NoFilter\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filtername in filternames:\n",
    "    name = get_experiment_names(filtername)\n",
    "    print(filtername, cumsum[\"DRD2\"][filtername][\"SMILES\"][-1], cumsum[\"DRD2\"][name][\"SMILES\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_experiment = {}\n",
    "similarity_experiment = {} \n",
    "outputmode_experiment = {}\n",
    "\n",
    "temperature_experiment = {}\n",
    "experience_experiment = {}\n",
    "\n",
    "experiments_list = [bucket_experiment, similarity_experiment, outputmode_experiment, temperature_experiment, experience_experiment]\n",
    "\n",
    "for target in target_params:\n",
    "    for filtername in filternames:\n",
    "        bucket_experiment[filtername] = {}\n",
    "        similarity_experiment[filtername] = {}\n",
    "        outputmode_experiment[filtername] = {}\n",
    "            \n",
    "        for bucket_size in bucket_sizes:\n",
    "            bucket_size = default_bucket_size if filtername == \"NoFilter\" else bucket_size\n",
    "            experiment = \"_\".join(map(str,[target, filtername, default_minsimilarity, bucket_size, default_outputmode, default_temperature, default_experience_replay]))\n",
    "            if experiment not in  cumsum[target]:\n",
    "                print(experiment)\n",
    "            else:\n",
    "                bucket_experiment[filtername][bucket_size] = experiment                \n",
    "\n",
    "        for minsimilarity in minsimilarities:\n",
    "            minsimilarity = default_minsimilarity if filtername == \"NoFilter\" else minsimilarity\n",
    "            experiment = \"_\".join(map(str,[target, filtername, minsimilarity, default_bucket_size, default_outputmode, default_temperature, default_experience_replay]))\n",
    "            if experiment not in  cumsum[target]:\n",
    "                print(experiment)\n",
    "            else:\n",
    "                similarity_experiment[filtername][minsimilarity] = experiment  \n",
    "                \n",
    "\n",
    "        for outputmode in outputmodes:\n",
    "            outputmode = default_outputmode if filtername == \"NoFilter\" else outputmode\n",
    "            experiment = \"_\".join(map(str,[target, filtername, default_minsimilarity, default_bucket_size, outputmode, default_temperature, default_experience_replay]))\n",
    "            if experiment not in  cumsum[target]:\n",
    "                print(experiment)\n",
    "            else:\n",
    "                outputmode_experiment[filtername][outputmode] = experiment  \n",
    "\n",
    "                \n",
    "temperature_experiment[\"NoFilter\"] = {}\n",
    "filtername  = \"NoFilter\"\n",
    "for temperature in temperatures:\n",
    "    experiment = \"_\".join(map(str,[\"DRD2\", \"NoFilter\", default_minsimilarity, default_bucket_size, default_outputmode, temperature, default_experience_replay]))\n",
    "    if experiment not in  cumsum[target]:\n",
    "        print(experiment)\n",
    "    else:\n",
    "        temperature_experiment[filtername][temperature] = experiment  \n",
    "\n",
    "experience_experiment[\"NoFilter\"] = {}\n",
    "for experience_replay in experience_replays:\n",
    "    experiment = \"_\".join(map(str,[\"DRD2\", \"NoFilter\", default_minsimilarity, default_bucket_size, default_outputmode, default_temperature, experience_replay]))\n",
    "    if experiment not in  cumsum[target]:\n",
    "        print(experiment)\n",
    "    else:\n",
    "        experience_experiment[filtername][experience_replay] = experiment  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of unique actives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for target, params in target_params.items():\n",
    "    maxstep = params['maxstep']\n",
    "    minactivity = params['minactivity']\n",
    "    for valid_experiments in experiments_list:\n",
    "        for filtername, experiment_dict in valid_experiments.items():\n",
    "            for number, experiment in experiment_dict.items():\n",
    "                experiment_parts = experiment.split(\"_\")\n",
    "                if target != experiment_parts[0]:\n",
    "                    continue    \n",
    "                subset = memories[target][experiment].query(\"STEP < @maxstep and SCORE >= @minactivity\")\n",
    "                nb = len(set(subset[\"SMILES\"]))\n",
    "                print(f\"{target:8}{experiment:65}{nb:>6}\")\n",
    "            print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of unique Murcko Scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, params in target_params.items():\n",
    "    maxstep = params['maxstep']\n",
    "    minactivity = params['minactivity'] \n",
    "    for valid_experiments in experiments_list:\n",
    "        for filtername, experiment_dict in valid_experiments.items():\n",
    "            for number, experiment in experiment_dict.items():\n",
    "                experiment_parts = experiment.split(\"_\")\n",
    "                if target != experiment_parts[0]:\n",
    "                    continue    \n",
    "                subset = memories[target][experiment].query(\"STEP < @maxstep and SCORE >= @minactivity\")\n",
    "                nb = len(set(subset[\"Murcko Scaffold\"]))\n",
    "                print(f\"{target:8}{experiment:65}{nb:>6}\")\n",
    "            print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of unique Topological Scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, params in target_params.items():\n",
    "    maxstep = params['maxstep']\n",
    "    minactivity = params['minactivity']    \n",
    "    for valid_experiments in experiments_list:\n",
    "        for filtername, experiment_dict in valid_experiments.items():\n",
    "            for number, experiment in experiment_dict.items():\n",
    "                experiment_parts = experiment.split(\"_\")\n",
    "                if target != experiment_parts[0]:\n",
    "                    continue    \n",
    "                subset = memories[target][experiment].query(\"STEP < @maxstep and SCORE >= @minactivity\")\n",
    "                nb = len(set(subset[\"Topological Scaffold\"]))\n",
    "                print(f\"{target:8}{experiment:65}{nb:>6}\")\n",
    "            print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of exact SMILES matches from ExCAPE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for target, params in target_params.items():\n",
    "    \n",
    "    maxstep = params['maxstep']\n",
    "    minactivity = params['minactivity']    \n",
    "    if target == 'clogP':\n",
    "        continue\n",
    "    df = pd.read_pickle(f\"data/{target}/actives.pkl.gz\")\n",
    "    actives = set(df[\"RDKIT_SMILES\"])\n",
    "    for filtername in filternames:\n",
    "        subset = memories[target][filtername].query(\"STEP < @maxstep and SCORE >= @minactivity\")\n",
    "        \n",
    "        generated = set(subset[\"SMILES\"])\n",
    "        nb_overlap = len(actives.intersection(generated))\n",
    "        print(f\"{target}\\t{filtername:30}\\t{nb_overlap}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of ECFP6 analogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, params in target_params.items():\n",
    "    maxstep = params['maxstep']\n",
    "    minactivity = params['minactivity']        \n",
    "    for valid_experiments in experiments_list:\n",
    "        for filtername, experiment_dict in valid_experiments.items():\n",
    "            for number, experiment in experiment_dict.items():\n",
    "                experiment_parts = experiment.split(\"_\")\n",
    "                if target != experiment_parts[0]:\n",
    "                    continue    \n",
    "                subset = memories[target][experiment].query(\"STEP < @maxstep and SCORE >= @minactivity\")\n",
    "                subset = subset.drop_duplicates(\"SMILES\")\n",
    "                nb = len(subset.query(\"NN_dist >= 0.4\"))\n",
    "                percent = (nb / len(subset))*100\n",
    "                print(f\"{target:8}{experiment:65}{nb:>6}\\t{percent:.3}%\")\n",
    "            print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, params in target_params.items():\n",
    "    maxstep = params['maxstep']\n",
    "    minactivity = params['minactivity']    \n",
    "    for valid_experiments in experiments_list:\n",
    "        for filtername, experiment_dict in valid_experiments.items():\n",
    "            for number, experiment in experiment_dict.items():\n",
    "                experiment_parts = experiment.split(\"_\")\n",
    "                if target != experiment_parts[0]:\n",
    "                    continue    \n",
    "                subset = memories[target][experiment].query(\"STEP < @maxstep and SCORE >= @minactivity\")\n",
    "                subset = subset.drop_duplicates(\"SMILES\")\n",
    "                nb = len(subset.query(\"NN_dist_training >= 0.4\"))\n",
    "                percent = (nb / len(subset))*100\n",
    "                print(f\"{target:8}{experiment:65}{nb:>6}\\t{percent:.3}%\")\n",
    "            print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, params in target_params.items():\n",
    "    maxstep = params['maxstep']\n",
    "    minactivity = params['minactivity']\n",
    "    for valid_experiments in experiments_list:\n",
    "        for filtername, experiment_dict in valid_experiments.items():\n",
    "            for number, experiment in experiment_dict.items():\n",
    "                experiment_parts = experiment.split(\"_\")\n",
    "                if target != experiment_parts[0]:\n",
    "                    continue    \n",
    "                subset = memories[target][experiment].query(\"STEP < @maxstep and SCORE >= @minactivity\")\n",
    "                subset = subset.drop_duplicates(\"SMILES\")\n",
    "                nb = len(subset.query(\"NN_dist_test >= 0.4\"))\n",
    "                percent = (nb / len(subset))*100\n",
    "                print(f\"{target:8}{experiment:65}{nb:>6}\\t{percent:.3}%\")\n",
    "            print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "os.makedirs(f\"plots_revisions/\", exist_ok=True)\n",
    "# SMALL_SIZE = 8\n",
    "# MEDIUM_SIZE = 10\n",
    "# BIGGER_SIZE = 12\n",
    "\n",
    "# plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "# plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "# plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "# plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "# plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "# plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "# plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "filternames_in_plots = [\"No memory\", \"CompoundSimilarity memory\", \"IdenticalMurckoScaffold memory\", \"IdenticalCarbonSkeleton memory\", \"ScaffoldSimilarity memory\"]\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "#plt.style.use('bmh')\n",
    "fig = plt.figure(figsize=(5,6))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filternames_mapping = {k:v for k,v in zip(filternames,filternames_in_plots) }\n",
    "filternames_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [\"SMILES\", \"Murcko Scaffold\", \"Topological Scaffold\"]:\n",
    "    things_to_plot = {}\n",
    "    for filtername in filternames: \n",
    "        things_to_plot[filtername] = {}\n",
    "        for bucket in bucket_sizes: \n",
    "            experiment = get_experiment_names(filtername, bucket_size=bucket)\n",
    "            if experiment:\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "            else: \n",
    "                experiment = get_experiment_names(filtername)\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,6))\n",
    "    for filtername in filternames:\n",
    "        x = list(things_to_plot[filtername].keys())\n",
    "        y = list(things_to_plot[filtername].values())\n",
    "        ax.plot(x,y, label=filternames_mapping[filtername])\n",
    "    #lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "\n",
    "    if stuff == \"SMILES\":\n",
    "        print_ylabel = \"No. generated ECFP6 analogs\"\n",
    "    elif stuff == \"Murcko Scaffold\": \n",
    "        print_ylabel = \"No. generated Bemis Murcko scaffolds\"\n",
    "    else:\n",
    "        print_ylabel = \"No. generated carbon skeletons\"\n",
    "\n",
    "    ax.set_xlabel(\"Bucket Size\")\n",
    "    ax.set_ylabel(print_ylabel)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots_revisions/bucket_size_{stuff}.svg\", bbox_inches='tight')\n",
    "    lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "    plt.savefig(f\"plots_revisions/bucket_size_{stuff}_legend.svg\", bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [\"SMILES\", \"Murcko Scaffold\", \"Topological Scaffold\"]:\n",
    "    things_to_plot = {}\n",
    "    for filtername in filternames: \n",
    "        things_to_plot[filtername] = {}\n",
    "        for bucket in bucket_sizes: \n",
    "            experiment = get_experiment_names(filtername, bucket_size=bucket, experience_replay=True)\n",
    "            if experiment:\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "            else: \n",
    "                experiment = get_experiment_names(filtername, experience_replay=True)\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,6))\n",
    "    for filtername in filternames:\n",
    "        x = list(things_to_plot[filtername].keys())\n",
    "        y = list(things_to_plot[filtername].values())\n",
    "        ax.plot(x,y, label=filternames_mapping[filtername])\n",
    "    #lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "\n",
    "    if stuff == \"SMILES\":\n",
    "        print_ylabel = \"No. generated ECFP6 analogs\"\n",
    "    elif stuff == \"Murcko Scaffold\":\n",
    "        print_ylabel = \"No. generated Bemis Murcko scaffolds\"\n",
    "    else:\n",
    "        print_ylabel = \"No. generated carbon skeletons\"\n",
    "\n",
    "    ax.set_xlabel(\"Bucket Size\")\n",
    "    ax.set_ylabel(print_ylabel)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f\"plots_revisions/bucket_size_{stuff} with experience.svg\", bbox_inches='tight')\n",
    "    lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "    plt.savefig(f\"plots_revisions/bucket_size_{stuff} with experience_legend.svg\", bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for stuff in [\"SMILES\", \"Murcko Scaffold\", \"Topological Scaffold\"]:\n",
    "    things_to_plot = {}\n",
    "    for filtername in filternames: \n",
    "        things_to_plot[filtername] = {}\n",
    "        for minsimilarity in minsimilarities: \n",
    "            experiment = get_experiment_names(filtername, minsimilarity=minsimilarity)\n",
    "            if experiment:\n",
    "                things_to_plot[filtername][minsimilarity] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "            else: \n",
    "                experiment = get_experiment_names(filtername)\n",
    "                things_to_plot[filtername][minsimilarity] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,6))\n",
    "    for filtername in filternames:\n",
    "        x = list(things_to_plot[filtername].keys())\n",
    "        y = list(things_to_plot[filtername].values())\n",
    "        ax.plot(x,y, label=filternames_mapping[filtername])\n",
    "    #lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "    if stuff == \"SMILES\":\n",
    "        print_ylabel = \"No. generated ECFP6 analogs\"\n",
    "    elif stuff == \"Murcko Scaffold\":\n",
    "        print_ylabel = \"No. generated Bemis Murcko scaffolds\"\n",
    "    else:\n",
    "        print_ylabel = \"No. generated carbon skeletons\"\n",
    "\n",
    "    ax.set_xlabel(\"Minimum Similarity\")\n",
    "    ax.set_ylabel(print_ylabel)\n",
    "    plt.tight_layout()    \n",
    "    plt.savefig(f\"plots_revisions/minsimilairty_{stuff}.svg\", bbox_inches='tight')\n",
    "    lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "    plt.savefig(f\"plots_revisions/minsimilairty_{stuff}_legend.svg\", bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for stuff in [\"SMILES\", \"Murcko Scaffold\", \"Topological Scaffold\"]:\n",
    "    things_to_plot = {}\n",
    "    for filtername in filternames: \n",
    "        things_to_plot[filtername] = {}\n",
    "        for temperature in temperatures: \n",
    "            experiment = get_experiment_names(filtername, temperature=temperature)\n",
    "            if experiment:\n",
    "                things_to_plot[filtername][temperature] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "            else: \n",
    "                experiment = get_experiment_names(filtername)\n",
    "                things_to_plot[filtername][temperature] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,6))\n",
    "    for filtername in filternames:\n",
    "        x = list(things_to_plot[filtername].keys())\n",
    "        y = list(things_to_plot[filtername].values())\n",
    "        ax.plot(x,y, label=filternames_mapping[filtername])\n",
    "    #lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "    if stuff == \"SMILES\":\n",
    "        print_ylabel = \"No. generated ECFP6 analogs\"\n",
    "    elif stuff == \"Murcko Scaffold\":\n",
    "        print_ylabel = \"No. generated Bemis Murcko scaffolds\"\n",
    "    else:\n",
    "        print_ylabel = \"No. generated carbon skeletons\"\n",
    "\n",
    "    ax.set_xlabel(\"Temperature\")\n",
    "    ax.set_ylabel(print_ylabel)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots_revisions/temperature_{stuff}.svg\", bbox_inches='tight')\n",
    "    lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "    plt.savefig(f\"plots_revisions/temperature_{stuff}_legend.svg\", bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for stuff in [\"SMILES\", \"Murcko Scaffold\", \"Topological Scaffold\"]:\n",
    "    things_to_plot = {}\n",
    "    for filtername in filternames: \n",
    "        things_to_plot[filtername] = {}\n",
    "        for outputmode in outputmodes: \n",
    "            experiment = get_experiment_names(filtername, outputmode=outputmode)\n",
    "            if experiment:\n",
    "                things_to_plot[filtername][outputmode] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "            else: \n",
    "                experiment = get_experiment_names(filtername)\n",
    "                things_to_plot[filtername][outputmode] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,6))\n",
    "    for filtername in filternames:\n",
    "        x = list(things_to_plot[filtername].keys())\n",
    "        y = list(things_to_plot[filtername].values())\n",
    "        ax.plot(x,y, label=filternames_mapping[filtername])\n",
    "    #lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "    if stuff == \"SMILES\":\n",
    "        print_ylabel = \"No. generated ECFP6 analogs\"\n",
    "    elif stuff == \"Murcko Scaffold\":\n",
    "        print_ylabel = \"No. generated Bemis Murcko scaffolds\"\n",
    "    else:\n",
    "        print_ylabel = \"No. generated carbon skeletons\"\n",
    "\n",
    "    ax.set_xlabel(\"Output Mode\")\n",
    "    ax.set_ylabel(print_ylabel)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots_revisions/outputmode_{stuff}.svg\", bbox_inches='tight')\n",
    "    lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "    plt.savefig(f\"plots_revisions/outputmode_{stuff}_legend.svg\", bbox_extra_artists=(lgd,), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [\"SMILES\", \"Murcko Scaffold\", \"Topological Scaffold\"]:\n",
    "    fig, ax = plt.subplots(figsize=(5,6))\n",
    "    colors = sns.color_palette()[0:5]\n",
    "\n",
    "    things_to_plot = {}\n",
    "    for filtername in filternames: \n",
    "        things_to_plot[filtername] = {}\n",
    "        for bucket in bucket_sizes: \n",
    "            experiment = get_experiment_names(filtername, bucket_size=bucket, experience_replay=False)\n",
    "            if experiment:\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "            else: \n",
    "                experiment = get_experiment_names(filtername, experience_replay=False)\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "    \n",
    "    for i, filtername in enumerate(filternames):\n",
    "        x = list(things_to_plot[filtername].keys())\n",
    "        y = list(things_to_plot[filtername].values())\n",
    "        ax.plot(x,y,':', label=f\"{filternames_mapping[filtername]} without experience replay\", c=colors[i], alpha=0.7)\n",
    "    \n",
    "    \n",
    "    \n",
    "    things_to_plot = {}\n",
    "    for filtername in filternames: \n",
    "        things_to_plot[filtername] = {}\n",
    "        for bucket in bucket_sizes: \n",
    "            experiment = get_experiment_names(filtername, bucket_size=bucket, experience_replay=True)\n",
    "            if experiment:\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "            else: \n",
    "                experiment = get_experiment_names(filtername, experience_replay=True)\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "    \n",
    "\n",
    "    for filtername in filternames:\n",
    "        x = list(things_to_plot[filtername].keys())\n",
    "        y = list(things_to_plot[filtername].values())\n",
    "        ax.plot(x,y, label=f\"{filternames_mapping[filtername]} with experience replay\")\n",
    "    #lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if stuff == \"SMILES\":\n",
    "        print_ylabel = \"No. generated ECFP6 analogs\"\n",
    "    elif stuff == \"Murcko Scaffold\":\n",
    "        print_ylabel = \"No. generated Bemis Murcko scaffolds\"\n",
    "    else:\n",
    "        print_ylabel = \"No. generated carbon skeletons\"\n",
    "\n",
    "    ax.set_xlabel(\"Bucket Size\")\n",
    "    ax.set_ylabel(print_ylabel)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f\"plots_revisions/bucket_size_{stuff} with and without experience.svg\", bbox_inches='tight')\n",
    "    #lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [\"SMILES\"]:\n",
    "    fig, ax = plt.subplots(figsize=(5,6))\n",
    "    colors = sns.color_palette()[0:5]\n",
    "\n",
    "    things_to_plot = {}\n",
    "    for filtername in filternames: \n",
    "        things_to_plot[filtername] = {}\n",
    "        for bucket in bucket_sizes: \n",
    "            experiment = get_experiment_names(filtername, bucket_size=bucket, experience_replay=False)\n",
    "            if experiment:\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "            else: \n",
    "                experiment = get_experiment_names(filtername, experience_replay=False)\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    for i, filtername in enumerate(filternames):\n",
    "        x = list(things_to_plot[filtername].keys())\n",
    "        y = list(things_to_plot[filtername].values())\n",
    "        line = ax.plot(x,y,':', label=f\"{filternames_mapping[filtername]} without experience replay\", c=colors[i], alpha=0.7)\n",
    "        lines.append(line[0])\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if stuff == \"SMILES\":\n",
    "        print_ylabel = \"No. generated ECFP6 analogs\"\n",
    "    elif stuff == \"Murcko Scaffold\":\n",
    "        print_ylabel = \"No. generated Bemis Murcko scaffolds\"\n",
    "    else:\n",
    "        print_ylabel = \"No. generated carbon skeletons\"\n",
    "\n",
    "    ax.set_xlabel(\"Bucket Size\")\n",
    "    ax.set_ylabel(print_ylabel)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.4), ncol=3, borderaxespad=0, frameon=True)\n",
    "    ax.axis(\"off\")\n",
    "    for line in lines:\n",
    "        line.set_visible(False)\n",
    "    plt.savefig(f\"plots_revisions/legend dotted.svg\", bbox_extra_artists=(lgd,), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [\"SMILES\"]:\n",
    "    fig, ax = plt.subplots(figsize=(5,6))\n",
    "    colors = sns.color_palette()[0:5]\n",
    "\n",
    "    things_to_plot = {}\n",
    "    for filtername in filternames: \n",
    "        things_to_plot[filtername] = {}\n",
    "        for bucket in bucket_sizes: \n",
    "            experiment = get_experiment_names(filtername, bucket_size=bucket, experience_replay=True)\n",
    "            if experiment:\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "            else: \n",
    "                experiment = get_experiment_names(filtername, experience_replay=True)\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    for i, filtername in enumerate(filternames):\n",
    "        x = list(things_to_plot[filtername].keys())\n",
    "        y = list(things_to_plot[filtername].values())\n",
    "        line = ax.plot(x,y, label=f\"{filternames_mapping[filtername]} with experience replay\", c=colors[i], alpha=0.7)\n",
    "        lines.append(line[0])\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if stuff == \"SMILES\":\n",
    "        print_ylabel = \"No. generated ECFP6 analogs\"\n",
    "    elif stuff == \"Murcko Scaffold\":\n",
    "        print_ylabel = \"No. generated Bemis Murcko scaffolds\"\n",
    "    else:\n",
    "        print_ylabel = \"No. generated carbon skeletons\"\n",
    "\n",
    "    ax.set_xlabel(\"Bucket Size\")\n",
    "    ax.set_ylabel(print_ylabel)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.4), ncol=3, borderaxespad=0, frameon=True)\n",
    "    ax.axis(\"off\")\n",
    "    for line in lines:\n",
    "        line.set_visible(False)\n",
    "    plt.savefig(f\"plots_revisions/legend line.svg\", bbox_extra_artists=(lgd,), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [\"SMILES\"]:\n",
    "    fig, ax = plt.subplots(figsize=(5,6))\n",
    "    colors = sns.color_palette()[0:5]\n",
    "\n",
    "    things_to_plot = {}\n",
    "    for filtername in filternames: \n",
    "        things_to_plot[filtername] = {}\n",
    "        for bucket in bucket_sizes: \n",
    "            experiment = get_experiment_names(filtername, bucket_size=bucket, experience_replay=False)\n",
    "            if experiment:\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "            else: \n",
    "                experiment = get_experiment_names(filtername, experience_replay=False)\n",
    "                things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    for i, filtername in enumerate(filternames):\n",
    "        x = list(things_to_plot[filtername].keys())\n",
    "        y = list(things_to_plot[filtername].values())\n",
    "        line = ax.plot(x,y, label=f\"{filternames_mapping[filtername]}\", c=colors[i], alpha=0.7)\n",
    "        lines.append(line[0])\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if stuff == \"SMILES\":\n",
    "        print_ylabel = \"No. generated ECFP6 analogs\"\n",
    "    elif stuff == \"Murcko Scaffold\":\n",
    "        print_ylabel = \"No. generated Bemis Murcko scaffolds\"\n",
    "    else:\n",
    "        print_ylabel = \"No. generated carbon skeletons\"\n",
    "\n",
    "    ax.set_xlabel(\"Bucket Size\")\n",
    "    ax.set_ylabel(print_ylabel)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.4), ncol=3, borderaxespad=0, frameon=True)\n",
    "    ax.axis(\"off\")\n",
    "    for line in lines:\n",
    "        line.set_visible(False)\n",
    "    plt.savefig(f\"plots_revisions/legend.svg\", bbox_extra_artists=(lgd,), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig, ax = plt.subplots(nrows=3, ncols=2, sharex=True, sharey=True, figsize=(15,12))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "fig, ax = plt.subplots(nrows=3, ncols=2, sharex=False, sharey=\"row\", figsize=(12,15))\n",
    "colors = sns.color_palette()[0:5]\n",
    "    \n",
    "for row, stuff in enumerate([\"SMILES\", \"Murcko Scaffold\", \"Topological Scaffold\"]):\n",
    "\n",
    "    \n",
    "    for col, experience_replay in enumerate([True, False]):\n",
    "        things_to_plot = {}\n",
    "        for filtername in filternames: \n",
    "            things_to_plot[filtername] = {}\n",
    "            for bucket in bucket_sizes: \n",
    "                experiment = get_experiment_names(filtername, bucket_size=bucket, experience_replay=experience_replay)\n",
    "                if experiment:\n",
    "                    things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "                else: \n",
    "                    experiment = get_experiment_names(filtername, experience_replay=experience_replay)\n",
    "                    things_to_plot[filtername][bucket] = cumsum[\"DRD2\"][experiment][stuff][-1]\n",
    "\n",
    "\n",
    "        for filtername in filternames:\n",
    "            x = list(things_to_plot[filtername].keys())\n",
    "            y = list(things_to_plot[filtername].values())\n",
    "            ax[row,col].plot(x,y, label=f\"{filternames_mapping[filtername]}\")\n",
    "        #lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if stuff == \"SMILES\":\n",
    "        print_ylabel = \"No. generated ECFP6 analogs\"\n",
    "    elif stuff == \"Murcko Scaffold\":\n",
    "        print_ylabel = \"No. generated Bemis Murcko scaffolds\"\n",
    "    else:\n",
    "        print_ylabel = \"No. generated carbon skeletons\"\n",
    "        \n",
    "    ax[row,0].set_ylabel(print_ylabel)\n",
    "\n",
    "ax[-1,0].set_xlabel(\"Bucket Size\")\n",
    "ax[-1,1].set_xlabel(\"Bucket Size\")\n",
    "\n",
    "ax[0,0].set_title(r\"$\\bf{with\\ experience\\ replay}$\"+\"\\n\\n(a)\")\n",
    "ax[0,1].set_title(r\"$\\bf{without\\ experience\\ replay}$\"+\"\\n\\n(b)\")\n",
    "\n",
    "ax[1,0].set_title(\"(c)\")\n",
    "ax[1,1].set_title(\"(d)\")\n",
    "\n",
    "ax[2,0].set_title(\"(e)\")\n",
    "ax[2,1].set_title(\"(f)\")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"plots_revisions/bucket_size with and without experience.svg\", bbox_inches='tight')\n",
    "#lgd = ax.legend(loc='center left', bbox_to_anchor= (1.05, 0.5), ncol=1, borderaxespad=0, frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
